# ğŸš€ K6 Load Testing Tool

A comprehensive web-based load testing platform built with K6, Flask, and modern web technologies. Features standard Virtual User Control and Simple Rate Control modes for effective performance testing with detailed interactive reports.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![K6](https://img.shields.io/badge/K6-Load%20Testing-orange.svg)](https://k6.io/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)

## âœ¨ Features

### ğŸŒ **Web-Based Interface**
- Intuitive drag-and-drop file upload
- Real-time test progress monitoring
- Configuration options with expandable UI
- Responsive design for all devices

### ğŸ“Š **Interactive Reports**
- **Chart.js powered visualizations**: Response time trends, throughput charts, error rate graphs
- **Detailed analytics**: 95th percentile, peak users, timeline analysis
- **Export capabilities**: HTML reports with embedded charts and raw JSON data
- **Performance insights**: Endpoint-specific metrics and recommendations

### âš¡ **Load Testing Capabilities**
- **Dual Testing Methods**: Virtual User Control and Simple Rate Control
- **Custom test stages**: Configure ramp-up, steady state, and ramp-down phases
- **Multiple authentication**: Support for different user types with token rotation
- **Weighted endpoints**: Realistic traffic distribution across API endpoints
- **Think time simulation**: Configurable delays between requests
- **Rate control**: Basic requests-per-second targeting for capacity planning

### ğŸ”§ **Flexible Configuration**
- **JSON-based setup**: Easy endpoint configuration with validation
- **Multi-environment support**: Test staging, production, or development APIs
- **Header customization**: Custom headers, authorization tokens, content types
- **Request body templates**: Support for GET, POST, PUT, DELETE methods

### ğŸ“ˆ **Performance Monitoring**
- **Real-time status updates**: Live progress tracking and stage monitoring
- **Error detection**: Automatic error rate calculation and threshold alerts
- **Timeline analysis**: Request-by-request performance breakdown
- **Concurrent user tracking**: Monitor virtual user load patterns

## ğŸ—ï¸ Project Architecture

```
K6-Load-Testing/
â”œâ”€â”€ ğŸ“ data/                    # Data storage and results
â”‚   â”œâ”€â”€ ğŸ“¤ uploads/            # User uploaded test configurations
â”‚   â”œâ”€â”€ ğŸ“Š results/            # Raw K6 test results (JSON)
â”‚   â””â”€â”€ ğŸ“‹ reports/            # Generated HTML reports with charts
â”œâ”€â”€ ğŸ“ scripts/                # Automation and utility scripts
â”‚   â”œâ”€â”€ ğŸš€ run_tests.sh       # Standard test execution with specific endpoints
â”‚   â”œâ”€â”€ âš¡ quick_test.sh       # Quick test with latest uploaded file
â”‚   â””â”€â”€ ğŸ–¥ï¸  start_server.sh    # Web server with auto-restart and validation
â”œâ”€â”€ ğŸ“ src/                    # Source code and application logic
â”‚   â”œâ”€â”€ ğŸ“ k6/                # K6 JavaScript test modules
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ test_executor.js    # Main K6 test runner with stages
â”‚   â”‚   â”œâ”€â”€ ğŸ›£ï¸ routes.js          # Route management and token handling
â”‚   â”‚   â””â”€â”€ âœ… config_validator.js # JSON configuration validation
â”‚   â”œâ”€â”€ ğŸ“ utils/              # Python utility modules
â”‚   â”‚   â””â”€â”€ ğŸ“ˆ report_generator.py # HTML report with Chart.js integration
â”‚   â””â”€â”€ ğŸ“ web/               # Flask web application
â”‚       â”œâ”€â”€ ğŸŒ app.py          # Main Flask server with upload handling
â”‚       â”œâ”€â”€ ğŸ“ routes/         # API route handlers
â”‚       â”œâ”€â”€ ğŸ“ static/         # CSS, JavaScript, and assets
â”‚       â”‚   â”œâ”€â”€ ğŸ¨ css/        # Custom styling and themes
â”‚       â”‚   â””â”€â”€ âš¡ js/         # Frontend JavaScript logic
â”‚       â””â”€â”€ ğŸ“ templates/      # Jinja2 HTML templates
â”‚           â”œâ”€â”€ ğŸ  base.html        # Base template with Bootstrap
â”‚           â”œâ”€â”€ ğŸ“¤ index.html       # Main upload and configuration page
â”‚           â””â”€â”€ ğŸ“Š test_status.html # Real-time test monitoring
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“œ LICENSE                 # MIT License
â””â”€â”€ ğŸ“– README.md              # This documentation
```

## ğŸš€ Quick Start Guide

### Prerequisites

- **Python 3.8+** with pip
- **K6** load testing tool ([Download K6](https://k6.io/docs/getting-started/installation/))
- **Modern web browser** (Chrome, Firefox, Safari, Edge)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/KamalBagchi/Load-Tester.git
   cd K6-Load-Testing
   ```

2. **Set up Python virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Verify K6 installation**
   ```bash
   k6 version
   ```

## ğŸ¯ Getting Started

### Quick Start (3 Steps)

1. **ğŸš€ Start the Frontend**
   ```bash
   ./scripts/start_server.sh
   ```
   This will:
   - âœ… Validate all dependencies (Python, K6, pip)
   - âœ… Create virtual environment if needed
   - âœ… Install Python packages
   - âœ… Create required directories
   - âœ… Start Flask web server at **http://localhost:5000**

2. **ğŸŒ Open Web Interface**
   ```bash
   # Open in your browser:
   http://localhost:5000
   ```
   You'll see a modern web interface with:
   - ğŸ“¤ Drag & drop file upload
   - âš™ï¸ Test configuration options
   - ğŸ“Š Real-time test monitoring

3. **ğŸ§ª Run Your First Test**
   - **Upload** your `endpoints.json` file via the web interface
   - **Configure** test stages (optional - defaults provided)
   - **Click** "Start Load Test" button
   - **Monitor** real-time progress
   - **View** interactive HTML reports with charts

### Alternative: Command Line Testing

If you prefer command line or have existing endpoint files:

```bash
# Virtual User Control (VU-based) - Traditional load testing
./scripts/quick_test.sh
./scripts/run_tests.sh data/uploads/your-endpoints.json

# Request Rate Control (RPS-based) - Capacity testing
./scripts/run_rate_control.sh --type constant --rate 50 --duration 5m
./scripts/run_rate_control.sh --type ramping --max-vus 500
```

## ğŸ“‹ Detailed Usage

### ğŸ¯ Usage

#### Method 1: Web Interface (Recommended)

1. **Start the web server**
   ```bash
   ./scripts/start_server.sh
   # Or manually: cd src/web && python app.py
   ```

2. **Access the application**
   - Open [http://localhost:5000](http://localhost:5000) in your browser
   - The interface will load with Bootstrap styling and interactive elements

3. **Configure your test**
   - **Upload**: Drag and drop your `endpoints.json` file
   - **Configuration Settings**: Click "Show Advanced" to configure custom test stages
   - **Test Stages**: Set duration and target users for each phase
     - Stage 1: `1m` â†’ `0 users` (Initialization)
     - Stage 2: `10s` â†’ `10 users` (Ramp-up)
     - Stage 3: `40s` â†’ `10 users` (Steady state)
     - Stage 4: `10s` â†’ `0 users` (Ramp-down)
     - Stage 5: `2m` â†’ `0 users` (Cool-down)

4. **Monitor and analyze**
   - Real-time progress updates during test execution
   - Automatic report generation with interactive charts
   - Download detailed HTML reports for further analysis

#### Method 2: Command Line

**Virtual User Control (Traditional)**
```bash
# Quick test with latest uploaded endpoints file
./scripts/quick_test.sh

# Run test with specific endpoints file
./scripts/run_tests.sh data/uploads/your-endpoints.json
```

**Request Rate Control (Capacity Testing)**
```bash
# Constant rate testing
./scripts/run_rate_control.sh --type constant --rate 50 --duration 5m
./scripts/run_rate_control.sh --rate 100 --duration 10m --max-vus 300

# Ramping rate testing
./scripts/run_rate_control.sh --type ramping --max-vus 500

# View help for more options
./scripts/run_rate_control.sh --help
```

**Report Generation**
```bash
# Generate reports from existing results
python src/utils/report_generator.py data/results/your-test-results.json

# Start the web server manually
./scripts/start_server.sh
```

## ğŸ¯ Testing Methods

This platform supports **two distinct load testing approaches** to meet different testing objectives:

### 1. Virtual User Control (VU-based) 
**Best for**: User experience testing, realistic user behavior simulation
- Controls the number of **virtual users** making requests
- Each user follows realistic patterns with think times
- Request rate varies based on system performance
- More realistic user simulation

### 2. Request Rate Control (RPS-based)
**Best for**: Capacity planning, SLA validation, API throughput testing  
- Controls **requests per second** directly
- K6 automatically scales virtual users to maintain target rate
- Consistent load regardless of response times
- Perfect for capacity and performance testing

| Method | Controls | Request Rate | Best For |
|--------|----------|--------------|----------|
| Virtual User | # of Users | Variable | User Experience |
| Rate Control | Requests/sec | Fixed | Capacity Planning |

ğŸ“š **Detailed comparison**: See [docs/TESTING_METHODS.md](docs/TESTING_METHODS.md)

## ğŸ“‹ Configuration Format

### Endpoints Configuration (`endpoints.json`)

```json
{
  "base_url": "https://api.example.com",
  "report_title": "API Performance Test",
  "report_subtitle": "Load testing for production endpoints",
  "tokens": [
    {
      "token": "eyJhbGciOiJIUzI1NiIs...",
      "name": "ADMIN_TOKEN"
    },
    {
      "token": "eyJhbGciOiJIUzI1NiIs...",
      "name": "USER_TOKEN"
    }
  ],
  "endpoints": [
    {
      "name": "USER_LOGIN",
      "description": "User authentication endpoint",
      "method": "POST",
      "url": "/api/v1/auth/login",
      "body": {
        "email": "test@example.com",
        "password": "testpass123"
      },
      "headers": {
        "Content-Type": "application/json",
        "Authorization": "<USER_TOKEN>"
      },
      "weight": 30,
      "thinkTime": {
        "min": 1,
        "max": 3
      },
      "threshold_ms": 1000
    }
  ]
}
```

### Configuration Options

| Field | Type | Description | Example |
|-------|------|-------------|---------|
| `base_url` | String | API base URL | `"https://api.example.com"` |
| `report_title` | String | Report title | `"API Performance Test"` |
| `report_subtitle` | String | Report description | `"Production load testing"` |
| `tokens` | Array | Authentication tokens | `[{"token": "...", "name": "USER_TOKEN"}]` |
| `endpoints` | Array | Test endpoints | See endpoint configuration below |

### Endpoint Configuration

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `name` | String | âœ… | Unique endpoint identifier |
| `description` | String | âŒ | Human-readable description |
| `method` | String | âœ… | HTTP method (`GET`, `POST`, `PUT`, `DELETE`) |
| `url` | String | âœ… | Endpoint path (relative to `base_url`) |
| `body` | Object/null | âŒ | Request body for POST/PUT requests |
| `headers` | Object | âŒ | Custom headers (use `<TOKEN_NAME>` for token substitution) |
| `weight` | Number | âŒ | Request frequency weight (default: 10) |
| `thinkTime` | Object | âŒ | Delay between requests `{"min": 1, "max": 5}` |
| `threshold_ms` | Number | âŒ | Performance threshold in milliseconds |

## ğŸ“Š Report Features

### Interactive Charts
- **Response Time Trends**: Timeline visualization of response times
- **Throughput Analysis**: Requests per second over time
- **Error Rate Monitoring**: Success/failure ratio tracking
- **Percentile Analysis**: 95th percentile response time distribution

### Detailed Metrics
- **Test Summary**: Total requests, error rate, average response time
- **Peak Performance**: Maximum concurrent users and throughput
- **Endpoint Analysis**: Per-endpoint performance breakdown
- **Timeline Data**: Request-by-request performance logs

### Export Options
- **HTML Reports**: Self-contained files with embedded charts
- **JSON Data**: Raw test results for further analysis
- **Performance Insights**: Automated recommendations and alerts

## ï¿½ Automation Scripts

The project includes three powerful automation scripts located in the `scripts/` directory:

### ğŸš€ **`run_tests.sh`** - Standard Test Execution

**Purpose**: Execute K6 load tests with specific endpoint configurations and generate comprehensive reports.

**Usage**:
```bash
./scripts/run_tests.sh <endpoints-file.json>
```

**Features**:
- âœ… **Parameter validation**: Requires specific endpoints file
- âœ… **File existence check**: Validates file before execution
- âœ… **Automatic report generation**: Creates HTML reports with charts
- âœ… **Clean file handling**: Copies and cleans up temporary files
- âœ… **Detailed feedback**: Shows progress and completion status

**Example**:
```bash
# Run test with specific configuration
./scripts/run_tests.sh data/uploads/20250808_120143_endpoints.json

# Output:
# ğŸš€ Starting k6 load test with comprehensive reporting...
# ğŸ“Š Running k6 test with: 20250808_120143_endpoints.json
# ğŸ“ˆ Generating HTML report with interactive charts...
# âœ… Test completed! Generated files: ...
```

### âš¡ **`quick_test.sh`** - Instant Testing

**Purpose**: Quickly run tests using the most recently uploaded endpoints file.

**Usage**:
```bash
./scripts/quick_test.sh
```

**Features**:
- âœ… **Auto-discovery**: Finds the latest uploaded endpoints file
- âœ… **Smart validation**: Checks if upload directory exists and has files
- âœ… **File information**: Shows which file is being used and when it was uploaded
- âœ… **Zero configuration**: No parameters needed - just run and go

**Example**:
```bash
# Quick test with latest file
./scripts/quick_test.sh

# Output:
# ğŸš€ Quick K6 Load Test Runner
# ğŸ“ Using latest endpoints file: my-api-endpoints.json
# â° File uploaded: 2025-08-08 12:32:28
# ğŸš€ Starting k6 load test...
```

### ğŸ–¥ï¸ **`start_server.sh`** - Web Server Management

**Purpose**: Set up and start the Flask web server with comprehensive environment validation.

**Usage**:
```bash
./scripts/start_server.sh
```

**Features**:
- âœ… **Dependency validation**: Checks Python 3, pip3, and K6 installation
- âœ… **Environment setup**: Creates virtual environment if needed
- âœ… **Package management**: Installs/updates Python dependencies
- âœ… **Directory structure**: Creates required data directories
- âœ… **Permission handling**: Sets proper file permissions
- âœ… **Helpful errors**: Provides installation instructions for missing dependencies

**Example**:
```bash
# Start the web server
./scripts/start_server.sh

# Output:
# ğŸš€ Starting K6 Load Testing Web Interface...
# ğŸ”§ Activating virtual environment...
# ğŸ“š Installing/upgrading dependencies...
# ğŸ“ Creating directory structure...
# âœ… Setup complete!
# ğŸŒ Starting web server...
```

### ğŸ“‹ **Script Dependencies**

| Script | Requirements | Auto-Install |
|--------|-------------|--------------|
| `run_tests.sh` | K6, Python 3, endpoints file | âŒ Manual K6 install |
| `quick_test.sh` | K6, Python 3, uploaded files | âŒ Manual K6 install |
| `start_server.sh` | Python 3, pip3, K6 | âœ… Python packages only |

### ğŸ”„ **Script Workflow**

**Typical Usage Flow:**
```
1. ğŸ–¥ï¸  start_server.sh          â†’ Start web interface
2. ğŸŒ Web Interface             â†’ Upload endpoints.json file  
3. âš¡ quick_test.sh             â†’ Quick test with latest file
   OR
   ğŸš€ run_tests.sh <file>       â†’ Test with specific file
4. ğŸ“Š K6 Test Execution         â†’ Load testing in progress
5. ğŸ“ˆ HTML Report Generation    â†’ Interactive charts created
6. ğŸ‘€ View Results             â†’ Analyze performance data
```

**Script Relationships:**
- **`start_server.sh`** enables the web interface for file uploads
- **`quick_test.sh`** automatically finds and tests the latest uploaded file
- **`run_tests.sh`** provides control over which specific file to test
- All scripts generate comprehensive HTML reports with interactive charts

### ğŸ› ï¸ **Script Customization**

All scripts support customization through environment variables:

```bash
# Custom K6 options
export K6_OPTIONS="--vus 100 --duration 5m"
./scripts/run_tests.sh data/uploads/endpoints.json

# Custom Python executable
export PYTHON_CMD="python3.11"
./scripts/start_server.sh

# Custom output directory
export RESULTS_DIR="custom-results"
./scripts/quick_test.sh
```

## ï¿½ğŸ› ï¸ Development

### Technology Stack
- **Backend**: Python 3.8+ with Flask 2.3+
- **Frontend**: Bootstrap 5, Chart.js, Vanilla JavaScript
- **Load Testing**: K6 with JavaScript test scripts
- **Reports**: Python with Chart.js integration
- **Data Storage**: JSON files with structured organization

### Development Setup

1. **Install development dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Run in development mode**
   ```bash
   cd src/web
   export FLASK_ENV=development
   python app.py
   ```

3. **File watching for auto-reload**
   ```bash
   # The Flask app supports auto-reload in development mode
   python app.py --debug
   ```

### Project Components

#### Flask Web Application (`src/web/`)
- **`app.py`**: Main Flask server with file upload, test execution, and status monitoring
- **`templates/`**: Jinja2 templates with Bootstrap styling and interactive JavaScript
- **`static/`**: CSS styling and frontend JavaScript for enhanced user experience

#### K6 Test Scripts (`src/k6/`)
- **`test_executor.js`**: Main K6 script with configurable stages and metrics
- **`routes.js`**: Route management with weighted distribution and token rotation
- **`config_validator.js`**: JSON schema validation for endpoint configurations

#### Report Generation (`src/utils/`)
- **`report_generator.py`**: HTML report generation with Chart.js integration
- Supports timeline analysis, performance metrics, and interactive visualizations

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **Push to the branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

### Development Guidelines
- Follow Python PEP 8 styling guidelines
- Add comprehensive tests for new features
- Update documentation for API changes
- Ensure backward compatibility

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### MIT License Summary
- âœ… Commercial use
- âœ… Modification
- âœ… Distribution
- âœ… Private use
- âŒ Liability
- âŒ Warranty

## ğŸ†˜ Support & Troubleshooting

### Common Issues

**Q: "FileNotFoundError" when uploading files**
- **Solution**: Ensure the `data/uploads/` directory exists and has write permissions
- **Script Check**: Run `./scripts/start_server.sh` to create required directories

**Q: K6 tests not running**
- **Solution**: Verify K6 is installed and accessible in your PATH (`k6 version`)
- **Installation**: Follow instructions from `./scripts/start_server.sh` error messages

**Q: Reports not generating**
- **Solution**: Check Python dependencies are installed (`pip list | grep Flask`)
- **Quick Fix**: Run `./scripts/start_server.sh` to install/update dependencies

**Q: Custom stages not applying**
- **Solution**: Ensure you're using the web interface configuration settings to configure stages
- **Alternative**: Use `./scripts/run_tests.sh` with properly configured endpoints file

**Q: Script permission denied**
- **Solution**: Make scripts executable: `chmod +x scripts/*.sh`
- **Verification**: Check with `ls -la scripts/`

**Q: "No endpoint files found" error**
- **Solution**: Upload endpoints.json through web interface first
- **Check**: Verify files exist with `ls data/uploads/*.json`

**Q: Virtual environment issues**
- **Solution**: Remove `.venv` directory and run `./scripts/start_server.sh` again
- **Manual Fix**: `rm -rf .venv && python3 -m venv .venv`

### Script-Specific Troubleshooting

| Script | Common Issue | Solution |
|--------|-------------|----------|
| `quick_test.sh` | "No endpoint files found" | Upload files via web interface first |
| `run_tests.sh` | "Usage: ./scripts/run_tests.sh <file>" | Provide specific endpoints file path |
| `start_server.sh` | "Python 3 is required" | Install Python 3.8+ from python.org |
| All scripts | "Permission denied" | Run `chmod +x scripts/*.sh` |

### Getting Help

- **Issues**: [GitHub Issues](https://github.com/KamalBagchi/Load-Tester/issues)
- **Documentation**: Check this README and inline code comments
- **K6 Documentation**: [Official K6 Docs](https://k6.io/docs/)

---

**Made with â¤ï¸ by [Kamal Nayan Bagchi](https://github.com/KamalBagchi)**
